{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4288559-7591-4ac4-b0dd-5bbaef8a67f9",
   "metadata": {},
   "source": [
    "# Timing Part 2: Refining a known timing solution\n",
    "\n",
    "Most of the time in PTA science, we're not starting from scratch -- someone else has already built a good timing solution for the pulsars we're analyzing. \n",
    "\n",
    "However, every time we add more data, we need to re-fit the timing model. This is partly to make sure nothing has happened that makes our model less accurate than we expected, but it's also partly because the more data we add, the more detailed our timing model can become. \n",
    "\n",
    "Remember, when we first discovered a pulsar, we only had a few pieces of information, but we could add more just by having a couple hundred TOAs. PTA pulsars can have thousands or tens of thousands of TOAs -- this allows us to make our datasets more and more robust.\n",
    "\n",
    "In the first section of the tutorial, we'll load a small set of TOAs with a slightly out-of-date timing model and update the model. In the second part of the tutorial, we'll load a real IPTA dataset and update the timing model. \n",
    "\n",
    "After you complete a guided version of Tutorial 2, you can use Tutorial 2.5 (a clean version with fewer comments) to check solutions for the additional pulsars you will have in your PTA. There are par, tim, and config files included for 12 pulsars, but you'll probably want to pick one pulsar per group member rather than timing *all* of the pulsars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b0aa51-e41b-47ff-997b-20e2105821c7",
   "metadata": {},
   "source": [
    "# Loading the relevant sofware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626acd74-dbda-4a4e-a820-8a2e85cb7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell imports the software we'll use in our analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "from io import StringIO\n",
    "import pint.fitter\n",
    "from pint.models import get_model\n",
    "from pint.toa import get_TOAs\n",
    "from pint.residuals import Residuals\n",
    "from pint.simulation import make_fake_toas_uniform\n",
    "import pint.logging\n",
    "# Advanced User Note: if you would like to see the DEBUG and INFO statements associated with PINT functions, \n",
    "# comment out the following line. These are not necessary for learners, but can be useful for experts.\n",
    "pint.logging.setup(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d51c2d-37e7-4e2d-9df6-66708b6e53da",
   "metadata": {},
   "source": [
    "# Timing a known pulsar (Simple version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa808ab-ecf7-48f5-9ac5-39ea978e10f4",
   "metadata": {},
   "source": [
    "When we already have a pretty good timing solution, we won't build our par file from scratch like we did in the first tutorial. Instead, we'll use PINT tools to load a par and tim file. (Along the way, we are essentially going to re-build the function `do_timing` that we had in Tutorial 1).\n",
    "\n",
    "We'll begin by setting up variables that represent the par and tim file names. Our files live in folders called `par` and `tim` respectively and are named `NGC6440E.par` and `NGC6440E.tim`.\n",
    "\n",
    "**Question:** \\\n",
    "Why is it valuable to use variables for the par and tim filenames rather than typing them into the commands for loading models and data directly?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e1f02-68ba-4a9d-948c-df8c9ad373e5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8d4245-90bc-4a63-a8fa-0ea36a0a7f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "parfile = \n",
    "timfile = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19183fd3-386e-4d7e-afb2-76e1b1338123",
   "metadata": {},
   "source": [
    "Now use PINT to load the timing model and the TOAs with `get_model` and `get_TOAs` respectively.\n",
    "\n",
    "Note that we want to specify an ephemeris in `get_TOAs` so that `t = get_TOAs(your-tim, ephem='DE440')`. We don't need any additional options with `get_model`.\n",
    "\n",
    "**Activity:**\\\n",
    "Load the TOAs and model found in the tim and par file referenced above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a05358-1001-49fa-8345-4b49bb661ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to = \n",
    "mo = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83c3ecc-9766-4376-970a-26fddc4a4c48",
   "metadata": {},
   "source": [
    "Each of these objects has properties we can access. Within the TOAs, we can find the modified Julian Days that correspond to the observations with `toas.get_mjds()`. We can also find the error in each TOA using `toa.get_errors()`. For better units, formatting, we more commonly use the format `toas.get_errors().toas(u.us).value`. This will save the values in microseconds\n",
    "\n",
    "**Activity** \\\n",
    "In the cell below, find the MJDs and the errors for the TOAs imported above.\n",
    "\n",
    "**Questions**:\n",
    "- What is the first MJD in the tim file? What is the last MJD?\n",
    "- What is the average TOA error value?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375ed380-a010-4c70-abd4-9a4d77d72188",
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = \n",
    "err = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642a98bd-6011-45c0-a10d-43acf47b7580",
   "metadata": {},
   "source": [
    "We have tons of info in our model too -- perhaps the easiest way to access it is just to call the model in our notebook. This will show us all the parameters, what kind of parameter they are, the value for the parameter, if they're fit, and the units of each parameter\n",
    "\n",
    "**Activity**\\\n",
    "Show our model below (hint -- don't do anything too sophisticated, just type the model's variable name and run the cell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c44f15-a185-4b60-a602-22087f20ec0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "965b1386-341d-48d4-af82-7649019273f4",
   "metadata": {},
   "source": [
    "When we get a par file for a PTA pulsar, we know that at some time in the past, this model was a good fit to the data (we can often figure out roughly when by looking at the `START` and `END` parameters in the par file). But we also know that in any model fitting problem, if we add more data points, the best fit can change. So, our first task is to see how well the old model fits this data.\n",
    "\n",
    "To plot any model in PINT, we have to set up a fitter object. It is this fitter object that allows us to view residuals as well as to do the actual fitting process. PINT fitters are found in the PINT class `pint.fitter`. \n",
    "\n",
    "There are several types of fitter implemented in PINT, most of which are variations on a weighted least squares fit. In PTA analyses, the best option is generally the `DownhillGLSFitter`. This is a generalized least squares fitter (which unlike the very similar `DownhillWLSFitter` is compatible with correlated noise parameters like ECORR). The \"Downhill\" part refers to the degree to which the fitter requires convergence. \n",
    "\n",
    "The syntax for instantiating a fitter is `my_fitter = pint.fitter.DownhillGLSFitter(toas,model)`.\n",
    "\n",
    "If you're not sure what fitter to use, you can also use `pint.fitter.Fitter.auto(toas, model`.\n",
    "\n",
    "**Activity** \\\n",
    "Using the TOAs and model you've already loaded, set up a Downhill generalized least squares fitter in the space below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce112730-8735-48b9-9ba2-7cf12d2876fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab360033-5d82-42c8-8d8c-32f9affb5b64",
   "metadata": {},
   "source": [
    "Once we create a fitter, we are able to assess how well our model fits our data. We haven't done a fit yet, but this is a little quirk of PINT: that all the information about combining the model and data can be found in the fitter object. It is also possible to evaluate the some of this information (like the residuals between a model and data) without a fitter object, but frankly, it can be kind of a waste of time if we know we eventually want to fit a new model to the data!\n",
    "\n",
    "To access the residuals without setting up a fitter, we would use the `Residuals` class, e.g. `resids = Residuals(toas, model)`. Alternatively, any fitter object creates a residuals object, so we can access the residuals via the `my_fitter.resids`. \n",
    "\n",
    "Either way, residuals can be expressed either in terms of time (seconds) through `time_resids` or in terms of phase (turns) through `phase_resids`.\n",
    "\n",
    "A sample call, for a set of TOAs called `toas` and a fitter called `my_fitter`, presented in units of microseconds (`u.us`) would look like\n",
    "\n",
    "`resids = my_fitter.resids.time_resids.toas(u.us).value`\n",
    "\n",
    "**Activity**\\\n",
    "Generate pre-fit residuals for your fittter.\n",
    "\n",
    "Find the average pre-fit residual value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6462626c-338b-4965-b38c-8cfcebc756eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_prefit = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c65eb97-3417-4927-a734-49c4bc1f2aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79a42bda-bb4b-4191-9438-6322050caa15",
   "metadata": {},
   "source": [
    "Next, we'd like to make a plot. We want the plot to have Modified Julian Days on the x-axis, residuals on the y-axis, and we want the data points to have y-error bars. Because we want error bars, we'll use `plt.errorbar(x,y,yerr=errors)` instead of `plt.plot(x,y)`. \n",
    "\n",
    "**Activity**\\\n",
    "Make a residuals plot. Hint: You can look at Tutorial 1 for help on syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009cedaf-99e1-4704-b045-6b4bab3e566c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b625e53-ea01-456b-8184-1a2e3dd2738f",
   "metadata": {},
   "source": [
    "Assess the fit of your model to your data. \\\n",
    "**Question**\\\n",
    "How does this look? Do you think this is a good fit? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da141d7-0042-4981-9a1d-8e48154da1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67ecd2c3-38f2-4a18-8c35-e437a6719724",
   "metadata": {},
   "source": [
    "Now, let's actually run the fit. This is pretty straightforward -- we just type \n",
    "`my_fitter.fit_toas()`. We can also set a higher number of iterations for the fiter with the option `maxiter`\n",
    "\n",
    "**Activity** \\\n",
    "Run the fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f00bdea-9f27-4be3-bdd7-8e5787c4c6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9420550e-653e-40f4-bda5-e5184464123f",
   "metadata": {},
   "source": [
    "Now, save the post-fit residuals and plot again to see how our fitter is doing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e33bd-a6da-43af-ae7b-8890f94adb30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556cf6a6-c332-4b73-8e5a-992c2a5b4bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d10c47b4-479b-4437-9812-8455dbc23a91",
   "metadata": {},
   "source": [
    "**Question**\\\n",
    "Does this look like a better fit? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93360bfd-3da9-4fbd-875a-01a9ae6cece6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd901de2-0f36-469c-97c8-5544c6d4cc5f",
   "metadata": {},
   "source": [
    "We need to understand how the parameters changed, and we'd really like a more definite answer for \"How good was the fit?\" than \"Hmmm, looks nice?\" Fortunately, PINT has a built-in option for this. \n",
    "\n",
    "The fitter has a method `print_summary`, which we can access via `my_fitter.print_summary()`. This will print the number of TOAs present in the data, the number of parameters fit, the pre-fit weighted RMS residual & the post-fit weighted RMS residuals, the reduced chi-squared value for the fit, and a comparison of the initial and final values.\n",
    "\n",
    "**Activity**\\\n",
    "In the cell below, print the summary of your fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48a9e20-86ca-44ee-b0bd-e5e17c590ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0bacd6dc-f35f-43f6-97e2-1a80ca89eca4",
   "metadata": {},
   "source": [
    "**Question**\n",
    "- Based on the results of `print_summary` is your current solution a good fit to this data? How do you know?\n",
    "- What parameters changed in the fitting process? By how much?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bcbde9-fd76-4dc8-b2e8-fa381a299901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04aeecf2-373b-44b3-affe-e0f723fef33f",
   "metadata": {},
   "source": [
    "If we are content with our analysis, it's time to save our new model. This will allow us to pass along our solution to another PTA member or to come back to these data later and not have to duplicate effort. \n",
    "\n",
    "The command in PINT to save a new par file is generally `model.write_parfile('filename.par')`. However, we want to be sure we write out the new model we found with fitting, not our original input model. Therefore, we instead use the model inside the fitter -- accessed via `my_fitter.model`. \n",
    "\n",
    "**Activity**\\\n",
    "In the space below, save your new model as a par file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665c726-214e-4003-ae06-3ba9b4359b72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab00f48d-abcb-4092-aeb6-14c6f1778580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b9b7b3c-93dc-4b26-8500-9d56f542ebe9",
   "metadata": {},
   "source": [
    "# Doing this analysis \"for real\" -- using PINT Pal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26164098-80bc-46fc-8e15-e050b364c3f9",
   "metadata": {},
   "source": [
    "If you actually get involved in either NANOGrav PINT-based timing or IPTA data combination, you'll use a supplemental software package called PINT-Pal. PINT-Pal includes tools that make it easier to handle a large set of data, to make plots, to make nice summary documents and so on. \n",
    "\n",
    "One of the biggest changes in a PINT-Pal framework vs. a pure PINT framework is the addition of the \"config\" file. The \"config\" file is a text file in YAML (yet another markup language) format which saves information about the desired par file, tim file(s), fitting parameters, conventions for analysis, bad data points, and even noise analysis. \n",
    "\n",
    "In addition to inputing file paths, we also use the config file to tell PINT what parameters to fit. All parameters we want fit should be put in the line `free-params` as well as having a 1 next to the quantity in the par file. This seems a little clunky at first, but it has the huge advantage of providing an \"at a glance\" list of fit parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a31002-2340-46b3-9c69-3aaf2662f2ed",
   "metadata": {},
   "source": [
    "The PINT functionality is the same when using PINT-Pal; we've just hidden some of the details so that a big/difficult problem is easier to get our head around.\n",
    "\n",
    "This portion of the tutorial is just a quick re-do of the above tutorial with PINT-Pal functions, but if you plan to get involved in data combination, make sure to check out the separate dr3_student_workshop tutorial available here: https://github.com/gooddc/dr3_student_workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5a030e-72be-4266-912a-f1cfb6cd893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pint_pal as pp\n",
    "import pint_pal.lite_utils as lu\n",
    "import pint_pal.plot_utils as pu\n",
    "from pint_pal.timingconfiguration import TimingConfiguration\n",
    "from astropy import log\n",
    "from pint.fitter import ConvergenceFailure\n",
    "import pint.fitter\n",
    "import os\n",
    "import sys\n",
    "import copy\n",
    "from astropy.visualization import quantity_support\n",
    "quantity_support()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set logging level (PINT uses loguru)\n",
    "log.setLevel(\"INFO\") # Set desired verbosity of log statements (DEBUG/INFO/WARNING/ERROR)\n",
    "pint.logging.setup(level=\"ERROR\", usecolors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53414c84-dc87-49fd-8e9a-0cb92dd7719a",
   "metadata": {},
   "source": [
    "## Load data with PINT-Pal\n",
    "\n",
    "Several sample config files are provided in the `configs` folder. Pick whichever one you like. Open that file and take a look at what it contains.\n",
    "\n",
    "Then, fill in that config file name below and run the cell. \n",
    "\n",
    "This cell's primary function is `get_model_and_toas`, which will (as it says) combine `get_model` and `get_TOAs` from PINT. It also has some additional options, like using a pickle file to load a previously used set of model & TOAs. (This cell can take a while for large datasets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc5a70-d89b-4a7b-91eb-dc8f01d3333a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"configs/[yourconfigname].yaml\"  # fill in actual path\n",
    "par_directory = None   # default location\n",
    "tim_directory = None   # default location\n",
    "tc = TimingConfiguration(config, par_directory=par_directory, tim_directory=tim_directory)\n",
    "\n",
    "# To combine TOAs, assumption is that cuts have already been applied properly\n",
    "mo,to = tc.get_model_and_toas(apply_initial_cuts=False,usepickle=False, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f693d2-a393-46f5-b011-9f2cba93652c",
   "metadata": {},
   "source": [
    "Now let's do some data housekeeping tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb47f5-eab9-4475-868c-c4df44f9f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply manual cuts. This line allows the \"bad TOAs\" to be flagged out in the config file.\n",
    "tc.manual_cuts(to)\n",
    "\n",
    "# Computing pulse numbers ensures param changes in the model will not break phase connection\n",
    "to.compute_pulse_numbers(mo)\n",
    "\n",
    "# Set non-binary epochs to the center of the data span\n",
    "lu.center_epochs(mo,to)\n",
    "\n",
    "# Summarize TOAs present\n",
    "summary = to.get_summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edba551-c9ae-4727-92df-680a34ed6927",
   "metadata": {},
   "source": [
    "**Question:** Based on the summary above, what telescope do you think was used to collect these TOAs? How many TOAs are there?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa0808f-de6f-4999-8e01-b572dc8f04a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f1da161-9f20-488e-af23-81d7ea4dff99",
   "metadata": {},
   "source": [
    "## Build a fitter and plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038e89b0-360a-4589-8690-a86e3f027d95",
   "metadata": {},
   "source": [
    "Next, we'll construct a fitter object with our model and TOAs (loaded from the par and tim files) and make our first plots. Though we've made a fitter object using the PINT Pal tool `construct_fitter`, we haven't yet executed a fit -- that's why our plots are labeled as \"pre-fit.\"\n",
    "\n",
    "These plotting functions `plot_residuals_time` and `plot_residuals_orb` are really helpful PINT-Pal tools. The first plots residuals as a function of time, and has built in options to apply different colors and labels based on information in the tim file (like what telescope collected the data or what PTA the data are from). The second does much the same but as a function of binary orbital phase (if the pulsar is in a binary). If the pulsar is not in a binary, this cell creates only one plot. \n",
    "\n",
    "It's not default, but you can also add `save=True` to these calls to automatically save the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f8cee-fe99-4318-8fdb-ae3cc30c8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the fitter object and plot pre-fit residuals\n",
    "fo = tc.construct_fitter(to,mo)\n",
    "pu.plot_residuals_time(fo, restype='prefit', legend=True)\n",
    "if mo.is_binary:\n",
    "    pu.plot_residuals_orb(fo, restype='prefit', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150ca1d-3ab9-4475-82f1-061731a6088e",
   "metadata": {},
   "source": [
    "**Question:** What if any interesting features do you see in this residual plot? How does it compare to the plot you generated without using PINT-pal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5207be04-b66c-45ba-a4a1-c6c77173791c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4cfb9a10-ef0b-471a-b734-521ae13de2aa",
   "metadata": {},
   "source": [
    "## Fit a new model and evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced14c93-48ce-4cfb-a0a0-faec3531e818",
   "metadata": {},
   "source": [
    "Now, we actually want to fit a new model to these TOAs. \n",
    "\n",
    "\n",
    "We'll first create a list of free parameters, then we'll go ahead and fit the model, using the fitting tools in PINT. One of the options available in our config is to set the type of fitter used. \n",
    "\n",
    "**Question:** Open the config file. What fitter are we using in the following cell?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94350043-4da0-4242-a5c2-bc795abfdae5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d1770c-e55c-4df9-8467-9d7cb1ed0c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set free params based on list in the config file (want to update JUMP handling differently soon)\n",
    "fo.model.free_params = tc.get_free_params(fo)\n",
    "\n",
    "# Do the fit\n",
    "try:\n",
    "    fo.fit_toas(maxiter=tc.get_niter())\n",
    "    fo.model.CHI2.value = fo.resids.chi2\n",
    "except ConvergenceFailure:\n",
    "    run_Ftest = False\n",
    "    log.warning('Failed to converge; moving on with best result, but should address before final version.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c798db2d-d99c-44db-a06a-cc1421f0f8f9",
   "metadata": {},
   "source": [
    "Our fitter should have converged okay. This step is fairly fast for our small data set, but it can take a long time for a larger dataset!\n",
    "\n",
    "Now let's examine how our fitter did. First, plots. Notice that now, they're labeled as \"postfit\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7027609-207e-4d50-a294-944aaa7959c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot post-fit residuals, print summary of results, write prenoise solution\n",
    "pu.plot_residuals_time(fo, restype='postfit', legend=True)\n",
    "if mo.is_binary:\n",
    "    pu.plot_residuals_orb(fo, restype='postfit', legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45b7104-568e-40c2-8c98-1199ffabf8cb",
   "metadata": {},
   "source": [
    "Now we can print a quick summary of our results. This is a great way to examine the difference between our pre-fit and post-fit parameters at a glance. Because all we did was add a bit more data, we shouldn't see a major difference in any of the parameters. If we do, that's a red flag. \n",
    "\n",
    "The PINT-Pal function check_convergence makes sure that our fitter has indeed converged. It will also warn us if we're not fitting parameters we should be fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7094c18e-7735-494a-8c14-38019ff1a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = fo.get_summary()\n",
    "\n",
    "lu.check_convergence(fo)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa38af6-1b9f-479b-b51c-786e7cd4d6e3",
   "metadata": {},
   "source": [
    "Finally, we'll want to save our par file. This function has exactly the same purpose as the PINT `write_par`, but the PINT-Pal version adds a little bit of standardized formatting/options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b397d-a36c-4870-8929-69f75232d020",
   "metadata": {},
   "outputs": [],
   "source": [
    "lu.write_par(fo,toatype=tc.get_toa_type(),addext='_prenoise')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ng20]",
   "language": "python",
   "name": "conda-env-ng20-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
