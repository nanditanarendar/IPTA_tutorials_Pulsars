{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60e95b2e",
   "metadata": {},
   "source": [
    "Notebook written by Bjorn Larsen - bjorn.larsen@nanograv.org\n",
    "\n",
    "This was written on short notice, please ask if something is confusing or not working (or incorrect)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b297ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config IPython.matplotlib.backend = \"retina\"\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "rcParams[\"savefig.dpi\"] = 300\n",
    "rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b45c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import os, pickle, logging, copy, json, git\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1a5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astropy.units as u\n",
    "import pint_pal.lite_utils as lu\n",
    "import pint_pal.plot_utils as pu\n",
    "from pint_pal.timingconfiguration import TimingConfiguration\n",
    "from enterprise.pulsar import Pulsar\n",
    "from enterprise.pulsar import BasePulsar\n",
    "from enterprise.signals import parameter, signal_base, gp_priors, gp_signals, white_signals, utils\n",
    "import enterprise.constants as const\n",
    "from enterprise_extensions.sampler import setup_sampler, get_parameter_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9606e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import la_forge.core as co\n",
    "import la_forge.diagnostics as dg\n",
    "import corner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73337355",
   "metadata": {},
   "source": [
    "# Intro to IPTA-style noise analysis\n",
    "\n",
    "This notebook introduces us to the process of performing noise analysis for IPTA style datasets. We generally categorizing timing noise as correlated changes in our timing residuals which are *stochastic* (effectively random based on our information about the system). Timing noise arises primarily due to changes in the ionized plasma of the interstellar medium (ISM) along the Earth-pulsar line of sight, spin fluctuations in the pulsar, or from gravitational waves. From the data analysis standpoint, we categorize different noises sources in terms of their *spectrum* (what we get if we take the Fourier transform of the timing residuals induced by the noise process) and their *chromaticity* (how does the amplitude of the noise vary as a function of the observed radio frequency). Ultimately we have to define some type of parameterized model that is flexible enough to fit for these processes without overfitting our data. For this we will move into using the `enterprise` software for fitting the noise processes, however in the end we can also include these noise processes to update our timing model fits in `pint`.\n",
    "\n",
    "To get a feel for the general process, let's first look at a toy dataset which contains an example of correlated noise, but not timing model effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348aa418",
   "metadata": {},
   "source": [
    "## Generate simplified data\n",
    "\n",
    "Here we will ignore the contributions of the timing model, and simply generate some timing residuals from scratch to illustrate the types of noise we will be looking at.\n",
    "\n",
    "First we ought to define the noise parameters ought to infer. We will have 3 white noise parameters (`efac`, `equad`, `ecorr`), 2 red noise parameters (`red_noise_A`, `red_noise_gam`), and 2 dm noise parameters (`dm_noise_A`, `dm_noise_gam`) which will introduce radio-frequency dependent noise. A and gamma describe the parameters of a power law spectrum in Fourier space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a308c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define noise parameters\n",
    "efac_true = 1.1\n",
    "equad_true = 0.3 # us\n",
    "ecorr_true = 0.5 # us\n",
    "red_noise_A_true = 1 # us at fref\n",
    "red_noise_gam_true = 4\n",
    "dm_noise_A_true = 0.5 # us at fref and nu = 1400 MHz\n",
    "dm_noise_gam_true = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596719a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params describe our toy data\n",
    "Nep = 200 # number of epochs\n",
    "Nnu = 4 # number of radio frequency observations per epoch\n",
    "Ntoas = Nep*Nnu\n",
    "Tmin = 0 # yr\n",
    "Tmax = 15 # yr\n",
    "Tspan = Tmax - Tmin\n",
    "nu_min = 800 # MHz\n",
    "nu_max = 2200 # MHz\n",
    "fref = 1/Tspan # 1/yr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3a61b4",
   "metadata": {},
   "source": [
    "Next let's generate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870bcd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1000)\n",
    "\n",
    "# generate randomly distributed data\n",
    "toas = np.sort(np.random.uniform(Tmin, Tmax, size=Nep)).repeat(Nnu)\n",
    "\n",
    "# define radio freuqencies of the TOAs, uniformly spaced from nu_min to nu_max\n",
    "freqs = np.array(list(np.linspace(nu_min, nu_max, Nnu))*Nep)\n",
    "\n",
    "# generate randomly distributed errors\n",
    "toaerr = np.random.uniform(0.1, 1, size=Ntoas)\n",
    "\n",
    "# generate Gaussian errors\n",
    "n = np.random.normal(size=Ntoas)\n",
    "\n",
    "# scale by the toa errors\n",
    "resids_noiseless = n*toaerr\n",
    "\n",
    "# plot the data with errorbars\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(toas, resids_noiseless, yerr=toaerr, fmt='.k', alpha=0.3, ms=10, zorder=1)\n",
    "# plot the data as a scatterplot with colors on top to show radio frequencies\n",
    "sc = plt.scatter(toas, resids_noiseless, c=freqs, cmap='Spectral', alpha=1, s=10,\n",
    "                 vmin=nu_min, vmax=nu_max, zorder=2)\n",
    "cbar = plt.colorbar(mappable=sc)\n",
    "cbar.ax.set_ylabel('Radio frequency (MHz)')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals ($\\mu$s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac13e9e0",
   "metadata": {},
   "source": [
    "This may be what our pulsar timing residuals look like after a good timing model fit. The errorbars all have different sizes, but if we divide the data by our errorbars we can see the data looks Gaussian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2aa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF of the normal distribution\n",
    "grid = np.linspace(-4,4,500)\n",
    "gauss_pdf = scipy.stats.norm().pdf(grid)\n",
    "\n",
    "# plot the data with errorbars\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4),sharey=True,width_ratios=[3,1])\n",
    "axes[0].scatter(toas, resids_noiseless/toaerr, c='k', alpha=1, s=10)\n",
    "axes[1].hist(resids_noiseless/toaerr, bins=30, color='k', alpha=0.5, orientation='horizontal', density=True)\n",
    "axes[1].plot(gauss_pdf, grid, '-k')\n",
    "axes[0].set_xlabel('TOAs (yr)')\n",
    "axes[0].set_ylabel(r'Normalized Residuals')\n",
    "fig.subplots_adjust(wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87213c3c",
   "metadata": {},
   "source": [
    "We have not added in any of our noise yet. First we will scale the noiseless residuals by some amount, which would correspond to what we would get if we underestimated all the errorbars. This is what we assume when we include the EFAC parameter in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db170463",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_with_efac = resids_noiseless*efac_true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82754c3",
   "metadata": {},
   "source": [
    "We will also add in some errors in quadrature. We could do this in two ways, either by regenerating the data following the formula\n",
    "\\begin{align}\n",
    "    \\sigma^2 = \\mathcal{F}^2\\sigma_{\\mathrm{ToA}}^2 + \\mathcal{Q}^2,\n",
    "\\end{align}\n",
    "where $\\mathcal{F}$ is EFAC and $\\mathcal{Q}$ is EQUAD, or we could just add independent measurement noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d725c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_independent = equad_true*np.random.normal(size=Ntoas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da46f2f",
   "metadata": {},
   "source": [
    "We can see now that the normalized residuals with this extra white noise is not a perfect match for the Gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3fa2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_with_measurement_noise = resids_with_efac + n_independent\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4),sharey=True,width_ratios=[3,1])\n",
    "axes[0].scatter(toas, resids_with_measurement_noise/toaerr, c='k', alpha=1, s=10)\n",
    "axes[1].hist(resids_with_measurement_noise/toaerr, bins=30, color='k',\n",
    "             alpha=0.5, orientation='horizontal', density=True)\n",
    "axes[1].plot(gauss_pdf, grid, '-k')\n",
    "axes[0].set_xlabel('TOAs (yr)')\n",
    "axes[0].set_ylabel(r'Normalized Residuals')\n",
    "fig.subplots_adjust(wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7b7793",
   "metadata": {},
   "source": [
    "Updating our errorbars accordingly will correct the distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fda497d",
   "metadata": {},
   "outputs": [],
   "source": [
    "toaerrs_with_measurement_noise = np.sqrt(efac_true**2*toaerr**2 + equad_true**2)\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(8,4),sharey=True,width_ratios=[3,1])\n",
    "axes[0].scatter(toas, resids_with_measurement_noise/toaerrs_with_measurement_noise, c='k', alpha=1, s=10)\n",
    "axes[1].hist(resids_with_measurement_noise/toaerrs_with_measurement_noise, bins=30, color='k',\n",
    "             alpha=0.5, orientation='horizontal', density=True)\n",
    "axes[1].plot(gauss_pdf, grid, '-k')\n",
    "axes[0].set_xlabel('TOAs (yr)')\n",
    "axes[0].set_ylabel(r'Normalized Residuals')\n",
    "fig.subplots_adjust(wspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb226f",
   "metadata": {},
   "source": [
    "That nice, but what if we have some type of white noise that affects all of the TOAs in an observation at once? Any type of astrophysical white noise will have this effect. One example is *pulse jitter*, which is caused by random variations in the pulse's shape. Possibly, we could get a similar effects from some short-timescale ISM processes (although this will also be *chromatic*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be4f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add jitter\n",
    "jitter = ecorr_true*np.random.normal(size=Nep).repeat(Nnu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965d9750",
   "metadata": {},
   "source": [
    "We can distinguish visually the difference between the independent measurement noise and jitter noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2f29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(toas, n_independent, c='k', alpha=1, s=10, label='Measurement noise (EQUAD)')\n",
    "plt.scatter(toas, jitter, c='C0', alpha=1, s=10, label='Jitter noise (ECORR)')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals ($\\mu$s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f43748e",
   "metadata": {},
   "source": [
    "Here's the total set of residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f4b1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_with_white_noise = resids_with_measurement_noise + jitter\n",
    "\n",
    "# plot the data with errorbars\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(toas, resids_with_white_noise, yerr=toaerr, fmt='.k', alpha=0.3, ms=10, zorder=1)\n",
    "# plot the data as a scatterplot with colors on top to show radio frequencies\n",
    "sc = plt.scatter(toas, resids_with_white_noise, c=freqs, cmap='Spectral', alpha=1, s=10,\n",
    "                 vmin=nu_min, vmax=nu_max, zorder=2)\n",
    "cbar = plt.colorbar(mappable=sc)\n",
    "cbar.ax.set_ylabel('Radio frequency (MHz)')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals ($\\mu$s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052027a4",
   "metadata": {},
   "source": [
    "Even though our timing residuals have three types of extra noise, it's very hard to distinguish between them by eye just looking at residuals plots!\n",
    "\n",
    "Next we'd like to look at time-correlated, or red noise. We'll generate some time correlated noise that runs along a power law spectrum using the FFT method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831da482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function adapted from enterprise\n",
    "def powerlaw(f, log10_A=-16, gamma=5, components=2, fref=1):\n",
    "    df = f[1] - f[0]\n",
    "    return (\n",
    "        (10**log10_A) ** 2 / 12.0 / np.pi**2 * fref ** (gamma - 3) * f ** (-gamma) * df\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e23609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Nf = 100\n",
    "f_grid = np.arange(1/Tspan, Nf/Tspan, 1/Tspan)\n",
    "rn_amp_spectrum = np.sqrt(powerlaw(f_grid, log10_A=np.log10(red_noise_A_true), gamma=red_noise_gam_true, fref=fref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b33ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(f_grid, rn_amp_spectrum, '.C0')\n",
    "plt.xlabel('Frequency (1/yr)')\n",
    "plt.ylabel(r'Amplitude spectrum ($\\mu$s)')\n",
    "plt.loglog()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6592a56c",
   "metadata": {},
   "source": [
    "We can generate a unique time series from this as the Fourier series of this spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4bf552",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random phases\n",
    "rn_phases = np.random.uniform(0, 2*np.pi, size=Nf)\n",
    "# get time series\n",
    "rn_t_series = 0\n",
    "for a, f, phase in zip(rn_amp_spectrum, f_grid, rn_phases):\n",
    "    rn_t_series += a*np.cos(2*np.pi*f*toas + phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c90a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(toas, rn_t_series, '.C0')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Red Noise Induced Timing Residual ($\\mu$s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450d5d49",
   "metadata": {},
   "source": [
    "As an illustration we can see how the time series changes as a function of the input value of the spectral index gamma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eb4a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gammas = np.flip(np.array([0,1,2,4,6]))\n",
    "fig, ax = plt.subplots(len(gammas), 1, figsize=(8,2*len(gammas)),sharex=True)\n",
    "for i, gam in enumerate(gammas):\n",
    "    temp_spectrum = np.sqrt(powerlaw(f_grid, log10_A=np.log10(red_noise_A_true), gamma=gam, fref=fref))\n",
    "    phases = np.random.uniform(0, 2*np.pi, size=Nf)\n",
    "    rn_t_series_temp = 0\n",
    "    for a, f, phase in zip(temp_spectrum, f_grid, phases):\n",
    "        rn_t_series_temp += a*np.cos(2*np.pi*f*toas + phase)\n",
    "    ax[i].plot(toas, rn_t_series_temp, '.C0', label=fr'$\\gamma = {gam}$')\n",
    "    ax[i].set_ylabel(fr'Red Noise ($\\mu$s)')\n",
    "    ax[i].legend()\n",
    "ax[-1].set_xlabel('TOAs (yr)')\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8f5c3d",
   "metadata": {},
   "source": [
    "Finally, let's generate some chromatic noise. The time series will be generated the exact same way as the achromatic red noise, but we'll introduce a radio frequency scaling $\\Delta t \\propto \\nu^{-2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeaa83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spectrum at 1400 MHz\n",
    "dm_amp_spectrum = np.sqrt(powerlaw(f_grid, log10_A=np.log10(dm_noise_A_true), gamma=dm_noise_gam_true, fref=fref))\n",
    "# random phases\n",
    "dm_phases = np.random.uniform(0, 2*np.pi, size=Nf)\n",
    "# get time series\n",
    "dm_t_series = 0\n",
    "for a, f, phase in zip(dm_amp_spectrum, f_grid, dm_phases):\n",
    "    dm_t_series += a*np.cos(2*np.pi*f*toas + phase)\n",
    "# apply scaling\n",
    "dm_t_series *= (1400/freqs)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6c6373",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "# plot the data as a scatterplot with colors on top to show radio frequencies\n",
    "sc = plt.scatter(toas, dm_t_series, c=freqs, cmap='Spectral', alpha=1, s=10,\n",
    "                 vmin=nu_min, vmax=nu_max, zorder=2)\n",
    "cbar = plt.colorbar(mappable=sc)\n",
    "cbar.ax.set_ylabel('Radio frequency (MHz)')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals ($\\mu$s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01bc9e3",
   "metadata": {},
   "source": [
    "Having data at multiple frequencies helps us distinguish DM noise from achromatic red noise! Otherwise we could never disentangle the effects of the two from the timing residuals.\n",
    "\n",
    "Finally, let's put all of our noises together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3aaff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "resids_noisy = resids_with_white_noise + rn_t_series + dm_t_series\n",
    "\n",
    "# plot the data with errorbars\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(toas, resids_noisy, yerr=toaerr, fmt='.k', alpha=0.3, ms=10, zorder=1)\n",
    "# plot the data as a scatterplot with colors on top to show radio frequencies\n",
    "sc = plt.scatter(toas, resids_noisy, c=freqs, cmap='Spectral', alpha=1, s=10,\n",
    "                 vmin=nu_min, vmax=nu_max, zorder=2)\n",
    "cbar = plt.colorbar(mappable=sc)\n",
    "cbar.ax.set_ylabel('Radio frequency (MHz)')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals ($\\mu$s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ea54ea",
   "metadata": {},
   "source": [
    "Next what we have to do is solve the data analysis problem of disentangling these effects.\n",
    "\n",
    "# Bayesian analysis\n",
    "\n",
    "We are going to use the `enterprise` pulsar timing analysis package to run a noise analysis on this data. Note that we have not done any actual pulsar timing, but we can still use this toy noisy dataset to show off some of what enterprise can do. Particularly, we've glossed over the fact that we will have to vary the timing model as we fit for the noise parameters. For simplicity, we will continue ignoring this for now, but we'll show how this is accounted for when we move on to real data.\n",
    "\n",
    "## enterprise setup\n",
    "\n",
    "First we'll define a simplified version of `enterprise.pulsar.Pulsar` which is used to take in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dfe55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakePulsar(BasePulsar):\n",
    "    '''\n",
    "    Inputs:\n",
    "    name of the pulsar\n",
    "    toas in units of seconds\n",
    "    residuals in units of seconds\n",
    "    toaerrs in units of seconds\n",
    "    freqs in units of MHz\n",
    "    '''\n",
    "    def __init__(self, name, toas, residuals, toaerrs, freqs, sort=True):\n",
    "        self._sort = sort\n",
    "\n",
    "        # these are TDB but not barycentered\n",
    "        self.name = name\n",
    "        self._toas = toas\n",
    "        self._residuals = residuals\n",
    "        self._toaerrs = toaerrs\n",
    "        self._ssbfreqs = freqs\n",
    "        \n",
    "        ntoas = len(self._toas)\n",
    "        \n",
    "        # add fake telescope names\n",
    "        self._telescope = np.array(['simulated']*ntoas)\n",
    "\n",
    "        # add fake flags/metadata for noise modeling\n",
    "        self._flags = {}\n",
    "        self._flags['pta'] = np.array(['Fake_PTA']*ntoas)\n",
    "        self._flags['f'] = np.array(['toy_data']*ntoas)\n",
    "        self._flags['group'] = np.array(['toy_data']*ntoas)\n",
    "\n",
    "        # convert flags to arrays\n",
    "        # TODO probably better way to do this\n",
    "        #      -- PINT always stores flags as strings\n",
    "        for key, val in self._flags.items():\n",
    "            if isinstance(val[0], u.quantity.Quantity):\n",
    "                self._flags[key] = np.array([v.value for v in val])\n",
    "            else:\n",
    "                self._flags[key] = np.array(val)\n",
    "\n",
    "        self.sort_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dec24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pulsar and convert TOAs, residuals, and errors into seconds\n",
    "epsr = FakePulsar('PSR', toas*365.25*86400, resids_noisy*1e-6, toaerr*1e-6, freqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94cd27a",
   "metadata": {},
   "source": [
    "This `FakePulsar` class is missing all of the astrophysical pieces normally contained therein. You can run `dir(epsr)` to see there are many attributes which we did not provide any means for this class to get the data for. However, the pulsar still contains the minimal data we need for noise modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b717347",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data again, just using the information in our pulsar class\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(epsr.toas, epsr.residuals, yerr=epsr.toaerrs, fmt='.k', alpha=0.3, ms=10, zorder=1)\n",
    "# plot the data as a scatterplot with colors on top to show radio frequencies\n",
    "sc = plt.scatter(epsr.toas, epsr.residuals, c=epsr.freqs, cmap='Spectral', alpha=1, s=10,\n",
    "                 vmin=nu_min, vmax=nu_max, zorder=2)\n",
    "cbar = plt.colorbar(mappable=sc)\n",
    "cbar.ax.set_ylabel('Radio frequency (MHz)')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f3f612",
   "metadata": {},
   "source": [
    "enterprise will natively interact with this pulsar class to setup the likelihood for our analysis. Next we can use enterprise to define the model components in a similar way to what we can use in the analysis of IPTA data (white noise, red noise, and DM variations). Specifically, we'll fit for our parameters using the following uniform and log-uniform priors:\n",
    "- EFAC: $\\mathcal{U}(0.01, 10)$\n",
    "- EQUAD: $\\log_{10}\\mathcal{U}(10^{-9}, 10^{-4})$\n",
    "- ECORR: $\\log_{10}\\mathcal{U}(10^{-9}, 10^{-4})$\n",
    "- $A_{RN}$: $\\log_{10}\\mathcal{U}(10^{-20}, 10^{-11})$\n",
    "- $\\gamma_{RN}$: $\\mathcal{U}(0, 7)$\n",
    "- $A_{DM}$: $\\log_{10}\\mathcal{U}(10^{-20}, 10^{-11})$\n",
    "- $\\gamma_{DM}$: $\\mathcal{U}(0, 7)$\n",
    "\n",
    "Note that log-uniform priors are uniform in log-space. These are useful as uniformative priors if you are not sure if the modeled process is actually present in the data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026df167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "efac = parameter.Uniform(0.01,10)\n",
    "log10_equad = parameter.Uniform(-9,-4)\n",
    "log10_ecorr = parameter.Uniform(-9,-4)\n",
    "red_noise_log10_A = parameter.Uniform(-20,-11)\n",
    "red_noise_gamma = parameter.Uniform(0,7)\n",
    "dm_noise_log10_A = parameter.Uniform(-20,-11)\n",
    "dm_noise_gamma = parameter.Uniform(0,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bb56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get our white noise signals\n",
    "ef = white_signals.MeasurementNoise(efac=efac)\n",
    "eq = white_signals.TNEquadNoise(log10_tnequad=log10_equad)\n",
    "ec = white_signals.EcorrKernelNoise(log10_ecorr)\n",
    "\n",
    "# define our red noise process\n",
    "pl = gp_priors.powerlaw(log10_A=red_noise_log10_A, gamma=red_noise_gamma)\n",
    "rn = gp_signals.FourierBasisGP(pl, components=30, name='red_noise')\n",
    "\n",
    "# define our dm noise process\n",
    "pl = gp_priors.powerlaw(log10_A=dm_noise_log10_A, gamma=dm_noise_gamma)\n",
    "dm_basis = utils.createfourierdesignmatrix_dm(nmodes=100)\n",
    "dm = gp_signals.BasisGP(pl, dm_basis, name='dm_gp')\n",
    "\n",
    "# total signal collection\n",
    "s = ef + eq + ec + rn + dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8fdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now act on pulsar object and create the PTA\n",
    "pta = signal_base.PTA(s(epsr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab20f6",
   "metadata": {},
   "source": [
    "This PTA object has everything we need to complete the analysis. We can call `pta.summary` to get a printout of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pta.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e8d77",
   "metadata": {},
   "source": [
    "Importantly, it can compute the likelihood of our data given a set of input noise parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fb74c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_log_likelihood(pta):\n",
    "    # generate a random parameter vector from the prior\n",
    "    params = {p.name:p.sample() for p in pta.params}\n",
    "    return pta.get_lnlikelihood(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1088ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "call_log_likelihood(pta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e77f9e",
   "metadata": {},
   "source": [
    "Check how long the likelihood call takes on your machine (should be a few ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit call_log_likelihood(pta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7f6821",
   "metadata": {},
   "source": [
    "## PTMCMCSampler setup\n",
    "\n",
    "We have our likelihood, now we can run an MCMC analysis using PTMCMCSampler. enterprise_extensions contains some nice tools to set this up for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3914b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = './toy_modelnoise_chains'\n",
    "if not os.path.isdir(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf02ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr = get_parameter_groups(pta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = setup_sampler(pta, outdir = outdir, groups = gr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad775ac4",
   "metadata": {},
   "source": [
    "We can run the sampler in notebook. Thankfully, a 7 parameter model will not take long to sample. Using 100000 iterations, it should take about 5 minutes. Our output parameter samples will be saved to an output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d00f694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can sample - chains will be saved to outdir\n",
    "Niter = 100000\n",
    "x0 = np.hstack([p.sample() for p in pta.params])\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e9ebaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sampler.sample(x0, Niter, burn=3_000, thin=10, SCAMweight=200, AMweight=100, DEweight=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c7ce4b",
   "metadata": {},
   "source": [
    "# Post processing\n",
    "\n",
    "Now we can evalute the results of our model to see if it make sense! We will use the `la_forge` package to do our post processing which contains lots of nice tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb3b7f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically burn the first 25% of the chain when we load\n",
    "core = co.Core(chaindir=outdir, params=pta.param_names, burn=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3670aa",
   "metadata": {},
   "source": [
    "First let's check the chain traces. The parameters should each look like fuzzy caterpillars if the analysis has converged. There are other most advanced types of checks we can perform on the chains to determine convergence if we need it (R hat statistic, autocorrelation lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49790d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.plot_chains(core, hist=False, ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192190bf",
   "metadata": {},
   "source": [
    "Next let's see the actual parameter distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb051312",
   "metadata": {},
   "outputs": [],
   "source": [
    "dg.plot_chains(core, hist=True, ncols=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ccdf0",
   "metadata": {},
   "source": [
    "We are using simulated data, so let's compare against the injected values as well. We can visualize this really nicely in the form of a corner plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbb3f7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we (attempt to) convert to enterprise units for the amp parameters\n",
    "truths = {\n",
    "    'PSR_dm_gp_gamma': dm_noise_gam_true,\n",
    "    'PSR_dm_gp_log10_A': np.log10((dm_noise_A_true*1e-6)**2/12/np.pi**2),\n",
    "    'PSR_efac': efac_true,\n",
    "    'PSR_log10_ecorr': np.log10(ecorr_true*1e-6),\n",
    "    'PSR_basis_ecorr_log10_ecorr': np.log10(ecorr_true*1e-6),\n",
    "    'PSR_log10_tnequad': np.log10(equad_true*1e-6),\n",
    "    'PSR_red_noise_gamma': red_noise_gam_true,\n",
    "    'PSR_red_noise_log10_A': np.log10((red_noise_A_true*1e-6)**2/12/np.pi**2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcbb4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fbcbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = ['PSR_efac', 'PSR_log10_ecorr', 'PSR_log10_tnequad',\n",
    "          'PSR_dm_gp_gamma', 'PSR_dm_gp_log10_A', 'PSR_red_noise_gamma', 'PSR_red_noise_log10_A']\n",
    "pidxs = [core.params.index(param) for param in params]\n",
    "plabels = [r'$\\mathcal{F}$', r'$\\log_{10}\\mathcal{Q}$', r'$\\log_{10}\\mathcal{J}$',\n",
    "           r'$\\gamma_{\\mathrm{DM}}$', r'$\\log_{10}A_{\\mathrm{DM}}$',\n",
    "           r'$\\gamma_{\\mathrm{RN}}$', r'$\\log_{10}A_{\\mathrm{RN}}$']\n",
    "figure = corner.corner(core.chain[core.burn:,pidxs], labels=plabels)\n",
    "\n",
    "truths_array = np.array([truths[param] for param in params])\n",
    "corner.overplot_lines(figure, truths_array, color=\"C0\")\n",
    "corner.overplot_points(figure, truths_array[None], marker=\"s\", color=\"C0\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920a3ff7",
   "metadata": {},
   "source": [
    "We did not get a perfect match to all the parameters, but it's pretty good for a crude analysis!\n",
    "\n",
    "**Exercise for the reader:** The DM noise amplitude appears to be higher than the injected value. This may actually be a mismatch between the units in enterprise and the units I use in the notebook. Can you find what the issue is?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d78a32",
   "metadata": {},
   "source": [
    "Finally, as we started by doing analysis of our timing residuals, it would be satisfying to check if the signals we are modeling actually match up with the signals we put into the data. We can do this in a straightforward way using `enterprise.utils.ConditionalGP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fc2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We remake the PTA here using EcorrBasisModel which will let us compute the GPs\n",
    "# You should verify that the likelihood is the same using both PTAs\n",
    "ec_basis = gp_signals.EcorrBasisModel(log10_ecorr)\n",
    "s_basis_ecorr = ef + eq + ec_basis + rn + dm\n",
    "pta_basis_ecorr = signal_base.PTA(s_basis_ecorr(epsr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42914bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note using basis ecorr changes the ecorr parameter name in the pta object\n",
    "pta_basis_ecorr.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8a2933",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = utils.ConditionalGP(pta_basis_ecorr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe4b388",
   "metadata": {},
   "source": [
    "Below we just input the true values \n",
    "\n",
    "**Exercise for the reader:** What happens if you add the max likleihood parameters for your noise analysis instead? The mean parameters? If you'd like to be fancy, you can setup a for loop to generate different realizations to sample from the posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dcaeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPs = gp.get_mean_processes(truths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a75fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02c7adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data again, just using the information in our pulsar class\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.errorbar(epsr.toas, epsr.residuals, yerr=epsr.toaerrs, fmt='.k', alpha=0.2, ms=10, zorder=1)\n",
    "plt.plot(epsr.toas, GPs['PSR_red_noise'], '-C3')\n",
    "plt.plot(epsr.toas, GPs['PSR_dm_gp'], '-C1')\n",
    "plt.plot(epsr.toas, GPs['PSR_basis_ecorr'], '-C0')\n",
    "plt.xlabel('TOAs (yr)')\n",
    "plt.ylabel(r'Residuals (s)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778112e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gps = GPs['PSR_red_noise'] + GPs['PSR_dm_gp'] + GPs['PSR_basis_ecorr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d7f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "toaerrs_adjusted = np.sqrt(truths['PSR_efac']**2*epsr.toaerrs**2 + (10**truths['PSR_log10_tnequad'])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90b1662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the data again, just using the information in our pulsar class\n",
    "fig, ax = plt.subplots(3,1,figsize=(8,7),sharex=True)\n",
    "ax[0].errorbar(epsr.toas, epsr.residuals, yerr=epsr.toaerrs, fmt='.k', alpha=0.2, ms=10, zorder=1)\n",
    "ax[0].plot(epsr.toas, all_gps, '-C2')\n",
    "ax[0].set_ylabel(r'Residuals (s)')\n",
    "ax[1].errorbar(epsr.toas, epsr.residuals - all_gps, yerr=epsr.toaerrs, fmt='.k', alpha=0.2, ms=10, zorder=1)\n",
    "ax[1].set_ylabel(r'Whitened Residuals (s)')\n",
    "ax[2].scatter(epsr.toas, (epsr.residuals - all_gps)/toaerrs_adjusted, c='k', alpha=0.2, s=10, zorder=1)\n",
    "ax[2].set_ylabel(r'Normalized Residuals')\n",
    "ax[2].set_xlabel('TOAs (yr)')\n",
    "plt.subplots_adjust(hspace=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580ceca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128753c6-f0d4-47d6-93ae-0e0139426a37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
